{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbcc9QS1tnBN"
   },
   "source": [
    "**ASSIGNMENT 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2Eeke4Z_EkW"
   },
   "source": [
    "1. Group #: 18\n",
    "   Member Names: Natasha Hussain, Daanish Khan \n",
    "\n",
    "   Member Student Numbers: 300122562, 300126840 \n",
    "   \n",
    "   Report Title: Classification Empirical Study "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMUnCICdyBbs"
   },
   "source": [
    "**Derived Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "aCWgl6PLKTDY"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    precision_score, \n",
    "    recall_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX9WQWGSwU2D"
   },
   "source": [
    "You have been given a list of datasets in the assignment description. Choose one of the datasets and provide the link below and read the dataset using pandas. You should provide a link to your own Github repository even if you are using a reduced version of a dataset from your TA's repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:** Airline Passenger Reviews \n",
    "\n",
    "**Description:** This dataset provides 64,017 data samples of passenger reviews. They are separated into 3 categories - Passive (Neutral), Detractors (Negative), and Promoters (Positive). The reduced version we will be using contains 10,761 samples. \n",
    "\n",
    "***[EXPLAIN WHAT WE DID TO THE DATA SETS HERE AND WHY]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "1Xx4qMCLKTDb"
   },
   "outputs": [],
   "source": [
    "#Load the dataset you chose.\n",
    "url = 'https://raw.githubusercontent.com/NatashaNaima/AI-NLPs/main/reduced_file_AirPassengerReviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "wg24OUV81Xgm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/NatashaNaima/AI-NLPs/main/reduced_file_AirPassengerReviews.csv\n"
     ]
    }
   ],
   "source": [
    "print(url)\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "AQ5nSY1HKTDd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_review</th>\n",
       "      <th>NPS Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London to Izmir via Istanbul. First time I'd ...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Istanbul to Bucharest. We make our check in i...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rome to Prishtina via Istanbul. I flew with t...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flew on Turkish Airlines IAD-IST-KHI and retu...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mumbai to Dublin via Istanbul. Never book Tur...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     customer_review  NPS Score\n",
       "0   London to Izmir via Istanbul. First time I'd ...    Passive\n",
       "1   Istanbul to Bucharest. We make our check in i...  Detractor\n",
       "2   Rome to Prishtina via Istanbul. I flew with t...  Detractor\n",
       "3   Flew on Turkish Airlines IAD-IST-KHI and retu...   Promoter\n",
       "4   Mumbai to Dublin via Istanbul. Never book Tur...  Detractor"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3pycllPKTDd"
   },
   "source": [
    "This is where you create the NLP pipeline. load() will download the correct model (English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "wQtSi8XuKTDe"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccqFArDyKTDf"
   },
   "source": [
    "Applying the pipeline to every sentences creates a Document where every word is a Token object.\n",
    "\n",
    "Doc: https://spacy.io/api/doc\n",
    "\n",
    "Token: https://spacy.io/api/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "WcaeMUL2KTDg"
   },
   "outputs": [],
   "source": [
    "#Apply nlp pipeline to the column that has your sentences.\n",
    "data['tokenized'] = data['customer_review'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "7i6ai1I8KTDg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_review</th>\n",
       "      <th>NPS Score</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London to Izmir via Istanbul. First time I'd ...</td>\n",
       "      <td>Passive</td>\n",
       "      <td>( , London, to, Izmir, via, Istanbul, ., First...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Istanbul to Bucharest. We make our check in i...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>( , Istanbul, to, Bucharest, ., We, make, our,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rome to Prishtina via Istanbul. I flew with t...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>( , Rome, to, Prishtina, via, Istanbul, ., I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flew on Turkish Airlines IAD-IST-KHI and retu...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>( , Flew, on, Turkish, Airlines, IAD, -, IST, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mumbai to Dublin via Istanbul. Never book Tur...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>( , Mumbai, to, Dublin, via, Istanbul, ., Neve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     customer_review  NPS Score  \\\n",
       "0   London to Izmir via Istanbul. First time I'd ...    Passive   \n",
       "1   Istanbul to Bucharest. We make our check in i...  Detractor   \n",
       "2   Rome to Prishtina via Istanbul. I flew with t...  Detractor   \n",
       "3   Flew on Turkish Airlines IAD-IST-KHI and retu...   Promoter   \n",
       "4   Mumbai to Dublin via Istanbul. Never book Tur...  Detractor   \n",
       "\n",
       "                                           tokenized  \n",
       "0  ( , London, to, Izmir, via, Istanbul, ., First...  \n",
       "1  ( , Istanbul, to, Bucharest, ., We, make, our,...  \n",
       "2  ( , Rome, to, Prishtina, via, Istanbul, ., I, ...  \n",
       "3  ( , Flew, on, Turkish, Airlines, IAD, -, IST, ...  \n",
       "4  ( , Mumbai, to, Dublin, via, Istanbul, ., Neve...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHRfZ2uEKTDh"
   },
   "source": [
    "A Token object has many attributes such as part-of-speech (pos_), lemma (lemma_), etc. Take a look at the documentation to see all attributes.\n",
    "\n",
    "The following function is an example on how you can fetch a specific pos tagging from a sentence. We return the lemmatization because we only want the infinitive word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***[EXPLAIN WHY WE CHOSE ADJECTIVES ONLY FOR THE FIRST DATASET]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "qw0a_2ySyUo2"
   },
   "outputs": [],
   "source": [
    "#create empty dataframes that will store derived datasets\n",
    "\n",
    "derived_dataset1 = pd.DataFrame(columns = ['Class', 'pos'])\n",
    "derived_dataset2 = pd.DataFrame(columns = ['Class', 'pos-np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Yeak1tAOKTDi"
   },
   "outputs": [],
   "source": [
    "def get_pos(sentence, wanted_pos): #wanted_pos refers to the desired pos tagging\n",
    "    verbs = []\n",
    "    for token in sentence:\n",
    "        if token.pos_ in wanted_pos:\n",
    "            verbs.append(token.lemma_) # lemma returns a number. lemma_ return a string\n",
    "    return ' '.join(verbs) # return value is as a string and not a list for countVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "147NRzwKKTDj"
   },
   "outputs": [],
   "source": [
    "derived_dataset1['pos'] = data['tokenized'].apply(lambda sent : get_pos(sent, ['ADJ']))\n",
    "derived_dataset1['Class'] = data['NPS Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "G_bUg_fVKTDk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passive</td>\n",
       "      <td>first good nice great Most contradictory littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>first last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>several past bad bad normal most useless few w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Promoter</td>\n",
       "      <td>excellent inflight extensive easy excellent in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>turkish other more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>stuck rude slow unhelpful only only positive g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>same technical complete armed civilian total m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>unfriendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Passive</td>\n",
       "      <td>comfortable small okay mid okay great friendly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>devastating final final turkish much unhelpful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class                                                pos\n",
       "0    Passive  first good nice great Most contradictory littl...\n",
       "1  Detractor                                         first last\n",
       "2  Detractor  several past bad bad normal most useless few w...\n",
       "3   Promoter  excellent inflight extensive easy excellent in...\n",
       "4  Detractor                                 turkish other more\n",
       "5  Detractor  stuck rude slow unhelpful only only positive g...\n",
       "6  Detractor  same technical complete armed civilian total m...\n",
       "7  Detractor                                         unfriendly\n",
       "8    Passive  comfortable small okay mid okay great friendly...\n",
       "9  Detractor  devastating final final turkish much unhelpful..."
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_dataset1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "AuGv-NnfKTDj"
   },
   "outputs": [],
   "source": [
    "def get_entities(sentence, wanted_entities):\n",
    "    entity = []\n",
    "    for ent in sentence.ents:\n",
    "        if ent.label_ in wanted_entities:\n",
    "            entity.append(ent.text)\n",
    "            \n",
    "    return ' '.join(entity) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***[EXPLAIN WHY WE CHOSE LOCATION AND ORGANIZATIONS FOR DATASET]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>pos-np</th>\n",
       "      <th>ent-np</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passive</td>\n",
       "      <td>first good nice great Most contradictory littl...</td>\n",
       "      <td>London Istanbul LHR Istanbul Ukraine London Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>first last</td>\n",
       "      <td>Istanbul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>several past bad bad normal most useless few w...</td>\n",
       "      <td>Rome Prishtina Istanbul Rome Prishtina Istanbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Promoter</td>\n",
       "      <td>excellent inflight extensive easy excellent in...</td>\n",
       "      <td>Turkish Airlines Turkish Airlines Turkish Airl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>turkish other more</td>\n",
       "      <td>Mumbai Dublin Istanbul Dublin Mumbai Mumbai Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>stuck rude slow unhelpful only only positive g...</td>\n",
       "      <td>Istanbul Budapest Dublin Turkish Airlines Ista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>same technical complete armed civilian total m...</td>\n",
       "      <td>Istanbul Algiers Algiers Algiers Turkish Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>unfriendly</td>\n",
       "      <td>Basel Cape Town Istanbul Istanbul Burger King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Passive</td>\n",
       "      <td>comfortable small okay mid okay great friendly...</td>\n",
       "      <td>Abu Dhabi Luxembourg Istanbul AUH-IST AUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>devastating final final turkish much unhelpful...</td>\n",
       "      <td>Turkish Airlines Turkish Airlines JetBlue Veni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class                                             pos-np  \\\n",
       "0    Passive  first good nice great Most contradictory littl...   \n",
       "1  Detractor                                         first last   \n",
       "2  Detractor  several past bad bad normal most useless few w...   \n",
       "3   Promoter  excellent inflight extensive easy excellent in...   \n",
       "4  Detractor                                 turkish other more   \n",
       "5  Detractor  stuck rude slow unhelpful only only positive g...   \n",
       "6  Detractor  same technical complete armed civilian total m...   \n",
       "7  Detractor                                         unfriendly   \n",
       "8    Passive  comfortable small okay mid okay great friendly...   \n",
       "9  Detractor  devastating final final turkish much unhelpful...   \n",
       "\n",
       "                                              ent-np  \n",
       "0  London Istanbul LHR Istanbul Ukraine London Is...  \n",
       "1                                           Istanbul  \n",
       "2  Rome Prishtina Istanbul Rome Prishtina Istanbu...  \n",
       "3  Turkish Airlines Turkish Airlines Turkish Airl...  \n",
       "4  Mumbai Dublin Istanbul Dublin Mumbai Mumbai Is...  \n",
       "5  Istanbul Budapest Dublin Turkish Airlines Ista...  \n",
       "6  Istanbul Algiers Algiers Algiers Turkish Airlines  \n",
       "7      Basel Cape Town Istanbul Istanbul Burger King  \n",
       "8          Abu Dhabi Luxembourg Istanbul AUH-IST AUH  \n",
       "9  Turkish Airlines Turkish Airlines JetBlue Veni...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_dataset2['ent-np'] = data['tokenized'].apply(lambda sent : get_entities(sent, ['ORG', 'GPE']))\n",
    "derived_dataset2['pos-np'] = data['tokenized'].apply(lambda sent : get_pos(sent, ['ADJ']))\n",
    "derived_dataset2['Class'] = data['NPS Score']\n",
    "derived_dataset2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pX4RgKhKTDk"
   },
   "source": [
    "Now that you have your derived datasets, you can move to perform your classificaton task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GhniwHtzfQt"
   },
   "source": [
    "**Perform Classification Task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "dataset_tfidf = TfidfVectorizer().fit_transform(data.customer_review)\n",
    "derived_dataset_1_tfidf = TfidfVectorizer().fit_transform(derived_dataset1.pos)\n",
    "derived_dataset_2_tfidf = TfidfVectorizer().fit_transform(np.concatenate((derived_dataset2['pos-np'].to_numpy(), derived_dataset2['ent-np'].to_numpy()), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistical Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistical_regression(x_train, x_test, y_train, y_test, C=1, solver='lbfgs'):\n",
    "\tmodel = LogisticRegression(max_iter=1000, C=1, solver='lbfgs').fit(x_train, y_train)\n",
    "\n",
    "\t# Make prediction from model\n",
    "\ty_pred = model.predict(x_test)\n",
    "\n",
    "\t# calculate accuracy and f1\n",
    "\taccuracy = accuracy_score(y_pred, y_test)\n",
    "\tf1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "\t# calculating micro and macro precision/recall\n",
    "\tmicro_precision = precision_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\tmicro_recall = recall_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "\t# calculating macro precision/recall \n",
    "\tmacro_precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\tmacro_recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\tevaluation = {'accuracy': accuracy, 'f1': f1, 'macro_p': macro_precision, 'macro_r':macro_recall, 'micro_p':micro_precision, 'micro_r': micro_recall}\n",
    "\treturn model, y_pred, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def mlp(x_train, x_test, y_train, y_test):\n",
    "\tmodel = MLPClassifier().fit(x_train, y_train)\n",
    "\n",
    "\t# Make prediction from model\n",
    "\ty_pred = model.predict(x_test)\n",
    "\n",
    "\t# calculate accuracy and f1\n",
    "\taccuracy = accuracy_score(y_pred, y_test)\n",
    "\tf1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "\t# calculating micro and macro precision/recall\n",
    "\tmicro_precision = precision_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\tmicro_recall = recall_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "\t# calculating macro precision/recall \n",
    "\tmacro_precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\tmacro_recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\tevaluation = {'accuracy': accuracy, 'f1': f1, 'macro_p': macro_precision, 'macro_r':macro_recall, 'micro_p':micro_precision, 'micro_r': micro_recall}\n",
    "\treturn model, y_pred, evaluation"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
