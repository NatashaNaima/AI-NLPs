{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbcc9QS1tnBN"
   },
   "source": [
    "**ASSIGNMENT 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2Eeke4Z_EkW"
   },
   "source": [
    "1. Group #: 18\n",
    "   Member Names: Natasha Hussain, Daanish Khan \n",
    "\n",
    "   Member Student Numbers: 300122562, 300126840 \n",
    "   \n",
    "   Report Title: Classification Empirical Study "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMUnCICdyBbs"
   },
   "source": [
    "**Derived Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "aCWgl6PLKTDY"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    precision_score, \n",
    "    recall_score\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX9WQWGSwU2D"
   },
   "source": [
    "You have been given a list of datasets in the assignment description. Choose one of the datasets and provide the link below and read the dataset using pandas. You should provide a link to your own Github repository even if you are using a reduced version of a dataset from your TA's repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:** Airline Passenger Reviews \n",
    "\n",
    "**Description:** This dataset provides 64,017 data samples of passenger reviews. They are separated into 3 categories - Passive (Neutral), Detractors (Negative), and Promoters (Positive). The reduced version we will be using contains 10,761 samples. \n",
    "\n",
    "Below we have 3 versions of the dataset that we will work with. The first dataset is simply a reduced dataset as we acquired from the source. Our second version of the datase is derived from the first to inlcude only part of speech tags. Our third and last dataset adds onto the second dataset by including part of speech tags as well as named entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "1Xx4qMCLKTDb"
   },
   "outputs": [],
   "source": [
    "#Load the dataset you chose.\n",
    "url = 'https://raw.githubusercontent.com/NatashaNaima/AI-NLPs/main/reduced_file_AirPassengerReviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "wg24OUV81Xgm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/NatashaNaima/AI-NLPs/main/reduced_file_AirPassengerReviews.csv\n"
     ]
    }
   ],
   "source": [
    "print(url)\n",
    "# dataset 1 : the reduced dataset\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "AQ5nSY1HKTDd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_review</th>\n",
       "      <th>NPS Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London to Izmir via Istanbul. First time I'd ...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Istanbul to Bucharest. We make our check in i...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rome to Prishtina via Istanbul. I flew with t...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flew on Turkish Airlines IAD-IST-KHI and retu...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mumbai to Dublin via Istanbul. Never book Tur...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     customer_review  NPS Score\n",
       "0   London to Izmir via Istanbul. First time I'd ...    Passive\n",
       "1   Istanbul to Bucharest. We make our check in i...  Detractor\n",
       "2   Rome to Prishtina via Istanbul. I flew with t...  Detractor\n",
       "3   Flew on Turkish Airlines IAD-IST-KHI and retu...   Promoter\n",
       "4   Mumbai to Dublin via Istanbul. Never book Tur...  Detractor"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3pycllPKTDd"
   },
   "source": [
    "This is where you create the NLP pipeline. load() will download the correct model (English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "wQtSi8XuKTDe"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccqFArDyKTDf"
   },
   "source": [
    "Applying the pipeline to every sentences creates a Document where every word is a Token object.\n",
    "\n",
    "Doc: https://spacy.io/api/doc\n",
    "\n",
    "Token: https://spacy.io/api/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "WcaeMUL2KTDg"
   },
   "outputs": [],
   "source": [
    "#Apply nlp pipeline to the column that has your sentences.\n",
    "data['tokenized'] = data['customer_review'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "7i6ai1I8KTDg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_review</th>\n",
       "      <th>NPS Score</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London to Izmir via Istanbul. First time I'd ...</td>\n",
       "      <td>Passive</td>\n",
       "      <td>( , London, to, Izmir, via, Istanbul, ., First...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Istanbul to Bucharest. We make our check in i...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>( , Istanbul, to, Bucharest, ., We, make, our,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rome to Prishtina via Istanbul. I flew with t...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>( , Rome, to, Prishtina, via, Istanbul, ., I, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flew on Turkish Airlines IAD-IST-KHI and retu...</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>( , Flew, on, Turkish, Airlines, IAD, -, IST, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mumbai to Dublin via Istanbul. Never book Tur...</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>( , Mumbai, to, Dublin, via, Istanbul, ., Neve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     customer_review  NPS Score  \\\n",
       "0   London to Izmir via Istanbul. First time I'd ...    Passive   \n",
       "1   Istanbul to Bucharest. We make our check in i...  Detractor   \n",
       "2   Rome to Prishtina via Istanbul. I flew with t...  Detractor   \n",
       "3   Flew on Turkish Airlines IAD-IST-KHI and retu...   Promoter   \n",
       "4   Mumbai to Dublin via Istanbul. Never book Tur...  Detractor   \n",
       "\n",
       "                                           tokenized  \n",
       "0  ( , London, to, Izmir, via, Istanbul, ., First...  \n",
       "1  ( , Istanbul, to, Bucharest, ., We, make, our,...  \n",
       "2  ( , Rome, to, Prishtina, via, Istanbul, ., I, ...  \n",
       "3  ( , Flew, on, Turkish, Airlines, IAD, -, IST, ...  \n",
       "4  ( , Mumbai, to, Dublin, via, Istanbul, ., Neve...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our derived datasets, we chose to use only adjectives for POS tagging. Since our datasets were reviews, we believed that adjectives would provide a clear enough picture of the general tone of each review to perform adequate classification. While we did consider doing a mix of tags to increase the amount of data we would have to work with, we believed in the end it would add more noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "qw0a_2ySyUo2"
   },
   "outputs": [],
   "source": [
    "#create empty dataframes that will store derived datasets\n",
    "\n",
    "derived_dataset1 = pd.DataFrame(columns = ['Class', 'pos'])\n",
    "derived_dataset2 = pd.DataFrame(columns = ['Class', 'pos-np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "Yeak1tAOKTDi"
   },
   "outputs": [],
   "source": [
    "def get_pos(sentence, wanted_pos): #wanted_pos refers to the desired pos tagging\n",
    "    verbs = []\n",
    "    for token in sentence:\n",
    "        if token.pos_ in wanted_pos:\n",
    "            verbs.append(token.lemma_) # lemma returns a number. lemma_ return a string\n",
    "    return ' '.join(verbs) # return value is as a string and not a list for countVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "147NRzwKKTDj"
   },
   "outputs": [],
   "source": [
    "derived_dataset1['pos'] = data['tokenized'].apply(lambda sent : get_pos(sent, ['ADJ']))\n",
    "derived_dataset1['Class'] = data['NPS Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "G_bUg_fVKTDk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passive</td>\n",
       "      <td>first good nice great Most contradictory littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>first last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>several past bad bad normal most useless few w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Promoter</td>\n",
       "      <td>excellent inflight extensive easy excellent in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>turkish other more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>stuck rude slow unhelpful only only positive g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>same technical complete armed civilian total m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>unfriendly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Passive</td>\n",
       "      <td>comfortable small okay mid okay great friendly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>devastating final final turkish much unhelpful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class                                                pos\n",
       "0    Passive  first good nice great Most contradictory littl...\n",
       "1  Detractor                                         first last\n",
       "2  Detractor  several past bad bad normal most useless few w...\n",
       "3   Promoter  excellent inflight extensive easy excellent in...\n",
       "4  Detractor                                 turkish other more\n",
       "5  Detractor  stuck rude slow unhelpful only only positive g...\n",
       "6  Detractor  same technical complete armed civilian total m...\n",
       "7  Detractor                                         unfriendly\n",
       "8    Passive  comfortable small okay mid okay great friendly...\n",
       "9  Detractor  devastating final final turkish much unhelpful..."
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_dataset1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "AuGv-NnfKTDj"
   },
   "outputs": [],
   "source": [
    "def get_entities(sentence, wanted_entities):\n",
    "    entity = []\n",
    "    for ent in sentence.ents:\n",
    "        if ent.label_ in wanted_entities:\n",
    "            entity.append(ent.text)\n",
    "            \n",
    "    return ' '.join(entity) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our second dataset, we included 3 named entities : organizations (airlines) and locations (travel destinations). These types of entities are relevant for classification as different airlines are known to meet certain levels of quality and different flights across airports experience varying levels of logistical consistency that affect flyers' experiences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>pos-np</th>\n",
       "      <th>ent-np</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passive</td>\n",
       "      <td>first good nice great Most contradictory littl...</td>\n",
       "      <td>London Istanbul LHR Istanbul Ukraine London Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>first last</td>\n",
       "      <td>Istanbul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>several past bad bad normal most useless few w...</td>\n",
       "      <td>Rome Prishtina Istanbul Rome Prishtina Istanbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Promoter</td>\n",
       "      <td>excellent inflight extensive easy excellent in...</td>\n",
       "      <td>Turkish Airlines Turkish Airlines Turkish Airl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>turkish other more</td>\n",
       "      <td>Mumbai Dublin Istanbul Dublin Mumbai Mumbai Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>stuck rude slow unhelpful only only positive g...</td>\n",
       "      <td>Istanbul Budapest Dublin Turkish Airlines Ista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>same technical complete armed civilian total m...</td>\n",
       "      <td>Istanbul Algiers Algiers Algiers Turkish Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>unfriendly</td>\n",
       "      <td>Basel Cape Town Istanbul Istanbul Burger King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Passive</td>\n",
       "      <td>comfortable small okay mid okay great friendly...</td>\n",
       "      <td>Abu Dhabi Luxembourg Istanbul AUH-IST AUH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>devastating final final turkish much unhelpful...</td>\n",
       "      <td>Turkish Airlines Turkish Airlines JetBlue Veni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Class                                             pos-np  \\\n",
       "0    Passive  first good nice great Most contradictory littl...   \n",
       "1  Detractor                                         first last   \n",
       "2  Detractor  several past bad bad normal most useless few w...   \n",
       "3   Promoter  excellent inflight extensive easy excellent in...   \n",
       "4  Detractor                                 turkish other more   \n",
       "5  Detractor  stuck rude slow unhelpful only only positive g...   \n",
       "6  Detractor  same technical complete armed civilian total m...   \n",
       "7  Detractor                                         unfriendly   \n",
       "8    Passive  comfortable small okay mid okay great friendly...   \n",
       "9  Detractor  devastating final final turkish much unhelpful...   \n",
       "\n",
       "                                              ent-np  \n",
       "0  London Istanbul LHR Istanbul Ukraine London Is...  \n",
       "1                                           Istanbul  \n",
       "2  Rome Prishtina Istanbul Rome Prishtina Istanbu...  \n",
       "3  Turkish Airlines Turkish Airlines Turkish Airl...  \n",
       "4  Mumbai Dublin Istanbul Dublin Mumbai Mumbai Is...  \n",
       "5  Istanbul Budapest Dublin Turkish Airlines Ista...  \n",
       "6  Istanbul Algiers Algiers Algiers Turkish Airlines  \n",
       "7      Basel Cape Town Istanbul Istanbul Burger King  \n",
       "8          Abu Dhabi Luxembourg Istanbul AUH-IST AUH  \n",
       "9  Turkish Airlines Turkish Airlines JetBlue Veni...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_dataset2['ent-np'] = data['tokenized'].apply(lambda sent : get_entities(sent, ['ORG', 'GPE']))\n",
    "derived_dataset2['pos-np'] = data['tokenized'].apply(lambda sent : get_pos(sent, ['ADJ']))\n",
    "derived_dataset2['Class'] = data['NPS Score']\n",
    "derived_dataset2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pX4RgKhKTDk"
   },
   "source": [
    "Now that we have our derived datasets, we can move to perform our classificaton task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GhniwHtzfQt"
   },
   "source": [
    "**Perform Classification Task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GhniwHtzfQt"
   },
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "dataset_tfidf = TfidfVectorizer().fit_transform(data.customer_review)\n",
    "derived_dataset_1_tfidf = TfidfVectorizer().fit_transform(derived_dataset1.pos)\n",
    "derived_dataset_2_tfidf = TfidfVectorizer().fit_transform(derived_dataset2['pos-np'].to_numpy() + derived_dataset2['ent-np'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistical Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistical regression estimates the probability of an outcome using a logistic function. The model is trained to find the optimal parameters in our dataset to maximize the likelihood of a particular review, and it provides a decision boundary for classification.\n",
    "\n",
    "To start we set out with mostly default parameters for logistical regression:\n",
    "\n",
    "We set our maximum interations to 1000 so that if convergence doesn't occur before then, our function will not take to long to run.\n",
    "\n",
    "We start here with C=1 to have a moderate regularization. Regularization is a technique used to prevent overfitting. A smaller C value specifies strong regularization, while a larger involves weaker regularization. \n",
    "\n",
    "We used Limited-memory Broyden–Fletcher–Goldfarb–Shanno ('lbfgs') for our optimization algorithm. Logistic regression can be solved using different optimization algorithms. Different solvers have different characteristics that perform better or worse dependant on the dataset size, features, and other factors. We chose LM BFGS because it is a popular choice for logistical regression on small to medium sized datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistical_regression(x_train, x_test, y_train, y_test, C=1, solver='lbfgs'):\n",
    "\tmodel = LogisticRegression(max_iter=1000, C=1, solver='lbfgs').fit(x_train, y_train)\n",
    "\n",
    "\t# Make prediction from model\n",
    "\ty_pred = model.predict(x_test)\n",
    "\n",
    "\t# calculate accuracy and f1\n",
    "\taccuracy = accuracy_score(y_pred, y_test)\n",
    "\tf1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "\t# calculating micro and macro precision/recall\n",
    "\tmicro_precision = precision_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\tmicro_recall = recall_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "\t# calculating macro precision/recall \n",
    "\tmacro_precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\tmacro_recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\tevaluation = {'accuracy': accuracy, 'f1': f1, 'macro_p': macro_precision, 'macro_r':macro_recall, 'micro_p':micro_precision, 'micro_r': micro_recall}\n",
    "\treturn model, y_pred, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MLP classification refers to the use of a Multi-Layer Perceptron for solving classification problems. They are known for their ability to capture complex relationships in data and perform well on a variety of tasks. However, they may require more data and computational resources compared to simpler models, and proper tuning of parameters is crucial for achieving good results.\n",
    "\n",
    "To start, we used the default parameters to classify our dataset. There are many paramters that can be changed and fine-tuned, but some notable ones to discuss here are:\n",
    "\n",
    "Hidden layer sizes: This paramter determines the number of neurons in each hidden layer. The default, that we use, is 100. \n",
    "\n",
    "Solver : The optimization algorithm used for weight opitmization. The default, that we use, is adam.\n",
    "\n",
    "Maximum iterations : The number of iterations for the solver to converge. When the model is not converging, we would set this to be very high so that we can choose a time to force it to converge. The default, that we use, is 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def mlp(x_train, x_test, y_train, y_test, max_iter='200', solver='adam', hidden_layer_sizes='(100,)'):\n",
    "\tmodel = MLPClassifier().fit(x_train, y_train)\n",
    "\n",
    "\t# Make prediction from model\n",
    "\ty_pred = model.predict(x_test)\n",
    "\n",
    "\t# calculate accuracy and f1\n",
    "\taccuracy = accuracy_score(y_pred, y_test)\n",
    "\tf1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "\t# calculating micro and macro precision/recall\n",
    "\tmicro_precision = precision_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\tmicro_recall = recall_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "\t# calculating macro precision/recall \n",
    "\tmacro_precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\tmacro_recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\tevaluation = {'accuracy': accuracy, 'f1': f1, 'macro_p': macro_precision, 'macro_r':macro_recall, 'micro_p':micro_precision, 'micro_r': micro_recall}\n",
    "\treturn model, y_pred, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natasha/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/natasha/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/natasha/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/natasha/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Results for Logistic Regression With Default Params (Original Dataset):\n",
      "accuracy: 0.7877\n",
      "f1: 0.8102\n",
      "macro_p: 0.6972\n",
      "macro_r: 0.6698\n",
      "micro_p: 0.7877\n",
      "micro_r: 0.7877\n",
      "\n",
      "Average Results for Logistic Regression With Default Params (Derived Dataset 1):\n",
      "accuracy: 0.7634\n",
      "f1: 0.7918\n",
      "macro_p: 0.6568\n",
      "macro_r: 0.6399\n",
      "micro_p: 0.7634\n",
      "micro_r: 0.7634\n",
      "\n",
      "Average Results for Logistic Regression With Default Params (Derived Dataset 2):\n",
      "accuracy: 0.7515\n",
      "f1: 0.7827\n",
      "macro_p: 0.6530\n",
      "macro_r: 0.6212\n",
      "micro_p: 0.7515\n",
      "micro_r: 0.7515\n",
      "\n",
      "Average Results for MLP With Default Params (Original Dataset):\n",
      "accuracy: 0.7570\n",
      "f1: 0.7611\n",
      "macro_p: 0.6605\n",
      "macro_r: 0.6640\n",
      "micro_p: 0.7570\n",
      "micro_r: 0.7570\n",
      "\n",
      "Average Results for MLP With Default Params (Derived Dataset 1):\n",
      "accuracy: 0.6883\n",
      "f1: 0.6899\n",
      "macro_p: 0.5859\n",
      "macro_r: 0.5990\n",
      "micro_p: 0.6883\n",
      "micro_r: 0.6883\n",
      "\n",
      "Average Results for MLP With Default Params (Derived Dataset 2):\n",
      "accuracy: 0.6653\n",
      "f1: 0.6633\n",
      "macro_p: 0.5720\n",
      "macro_r: 0.5777\n",
      "micro_p: 0.6653\n",
      "micro_r: 0.6653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "dataset_results_LR = []\n",
    "derived_dataset_1_results_LR = []\n",
    "derived_dataset_2_results_LR = []\n",
    "\n",
    "dataset_results_MLP = []\n",
    "derived_dataset_1_results_MLP = []\n",
    "derived_dataset_2_results_MLP = []\n",
    "\n",
    "def kfold_eval(dataset, target):\n",
    "\tresultsLR = []\n",
    "\tresultsMLP = []\n",
    "\tfor train_index, test_index in kf.split(dataset):\n",
    "\t\tx_train, x_test, y_train, y_test = dataset[train_index], dataset[test_index], target[train_index], target[test_index]\n",
    "\n",
    "\t\t_, _, results_LR = logistical_regression(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\t\t_, _, results_MLP = mlp(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\t\tresultsLR.append(results_LR)\n",
    "\t\tresultsMLP.append(results_MLP)\n",
    "\t\n",
    "\treturn resultsLR, resultsMLP\n",
    "\n",
    "dataset_results_LR, dataset_results_MLP = kfold_eval(dataset_tfidf, data['NPS Score'])\n",
    "derived_dataset_1_results_LR, derived_dataset_1_results_MLP = kfold_eval(derived_dataset_1_tfidf, derived_dataset1['Class'])\n",
    "derived_dataset_2_results_LR, derived_dataset_2_results_MLP = kfold_eval(derived_dataset_2_tfidf, derived_dataset2['Class'])\n",
    "\n",
    "dataset_results_LR_avg = {metric: sum(result[metric] for result in dataset_results_LR) / len(dataset_results_LR) for metric in dataset_results_LR[0]}\n",
    "derived_dataset_1_LR_avg = {metric: sum(result[metric] for result in derived_dataset_1_results_LR) / len(derived_dataset_1_results_LR) for metric in derived_dataset_1_results_LR[0]}\n",
    "derived_dataset_2_LR_avg = {metric: sum(result[metric] for result in derived_dataset_2_results_LR) / len(derived_dataset_2_results_LR) for metric in derived_dataset_2_results_LR[0]}\n",
    "\n",
    "dataset_results_MLP_avg = {metric: sum(result[metric] for result in dataset_results_MLP) / len(dataset_results_MLP) for metric in dataset_results_MLP[0]}\n",
    "derived_dataset_1_MLP_avg = {metric: sum(result[metric] for result in derived_dataset_1_results_MLP) / len(derived_dataset_1_results_MLP) for metric in derived_dataset_1_results_MLP[0]}\n",
    "derived_dataset_2_MLP_avg = {metric: sum(result[metric] for result in derived_dataset_2_results_MLP) / len(derived_dataset_2_results_MLP) for metric in derived_dataset_2_results_MLP[0]}\n",
    "\n",
    "print(\"Average Results for Logistic Regression With Default Params (Original Dataset):\")\n",
    "for metric, value in dataset_results_LR_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for Logistic Regression With Default Params (Derived Dataset 1):\")\n",
    "for metric, value in derived_dataset_1_LR_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for Logistic Regression With Default Params (Derived Dataset 2):\")\n",
    "for metric, value in derived_dataset_2_LR_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Original Dataset):\")\n",
    "for metric, value in dataset_results_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Derived Dataset 1):\")\n",
    "for metric, value in derived_dataset_1_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Derived Dataset 2):\")\n",
    "for metric, value in derived_dataset_2_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "LR = [dataset_results_LR_avg.get('accuracy', None) *100, derived_dataset_1_LR_avg.get('accuracy', None) *100, derived_dataset_2_LR_avg.get('accuracy', None) *100]\n",
    "MLP = [dataset_results_MLP_avg.get('accuracy', None)*100, derived_dataset_1_MLP_avg.get('accuracy', None)*100,derived_dataset_2_MLP_avg.get('accuracy', None)*100] \n",
    "index = ['Original Reduced Dataset', 'Derived Dataset 1','Derived Dataset 2']\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'Logistical Regression' : LR,\n",
    "        'MLP' : MLP\n",
    "    },\n",
    "    index=index\n",
    ")\n",
    "ax = df.plot.bar(rot=0, xlabel='Parameters', ylabel='Accuracy', title='Comparison of LR and MLP across datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both models, the original dataset provides most accurancy, first derived dataset with only POS performing notably worse and the second derived dataset worse still; across all datasets, logistical regression is consistently more accurate while MLP lags behind further and further with each dataset.\n",
    "\n",
    "Logistical Regression performs beter on smaller datasets. Our dataset has over 10 000 samples, which a lot compared to previous sets used for logistical regression in this class, is still relatively small when compared to the extremely large datasets that models like MLP were developed for. Additionally, we used only the default parameters of MLP. MLP has many parameters that can be finely tuned to increase accuracy based on the conditions our dataset is in.\n",
    "\n",
    "The first dataset contains pure raw text information from each review. This provides more features to associate with each result. Given the difference between the original dataset and the first derivation (-2% for LR and -6% for MLP) we believe there is lies other features in the raw text not included in adjectives nor our entities that increases the accuracy of these models. \n",
    "\n",
    "We also see that micro precision/recall perform better than our macro precision and recall. This shows us that our model is relying on larger classes to classify. In our case where we are purely looking out for what features result in good or bad reviews, this might actually be preferrable as it gives us an insight into certain qualities of the larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Changes for MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Change\n",
    "In our first modification to MLP, since our logistical regression outperformed our default MLP, we want to change our parameters to as closely match the process of our logistical regresion model. So we set our maximum interations to 1000 and use Limited-memory Broyden–Fletcher–Goldfarb–Shanno ('lbfgs') for our optimization algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "dataset_results_MLP = []\n",
    "derived_dataset_1_results_MLP = []\n",
    "derived_dataset_2_results_MLP = []\n",
    "\n",
    "def kfold_eval(dataset, target):\n",
    "\tresultsMLP = []\n",
    "\tfor train_index, test_index in kf.split(dataset):\n",
    "\t\tx_train, x_test, y_train, y_test = dataset[train_index], dataset[test_index], target[train_index], target[test_index]\n",
    "\n",
    "\t\t_, _, results_MLP = mlp(x_train, x_test, y_train, y_test,max_iter='1000', solver='lbfgs')\n",
    "\n",
    "\t\tresultsMLP.append(results_MLP)\n",
    "\t\n",
    "\treturn resultsLR, resultsMLP\n",
    "\n",
    "dataset_results_MLP = kfold_eval(dataset_tfidf, data['NPS Score'])\n",
    "derived_dataset_1_results_MLP = kfold_eval(derived_dataset_1_tfidf, derived_dataset1['Class'])\n",
    "derived_dataset_2_results_MLP = kfold_eval(derived_dataset_2_tfidf, derived_dataset2['Class'])\n",
    "\n",
    "dataset_results_MLP_avg = {metric: sum(result[metric] for result in dataset_results_MLP) / len(dataset_results_MLP) for metric in dataset_results_MLP[0]}\n",
    "derived_dataset_1_MLP_avg = {metric: sum(result[metric] for result in derived_dataset_1_results_MLP) / len(derived_dataset_1_results_MLP) for metric in derived_dataset_1_results_MLP[0]}\n",
    "derived_dataset_2_MLP_avg = {metric: sum(result[metric] for result in derived_dataset_2_results_MLP) / len(derived_dataset_2_results_MLP) for metric in derived_dataset_2_results_MLP[0]}\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Original Dataset):\")\n",
    "for metric, value in dataset_results_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Derived Dataset 1):\")\n",
    "for metric, value in derived_dataset_1_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Derived Dataset 2):\")\n",
    "for metric, value in derived_dataset_2_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of these parameter changes is that we see results closer to those of logistic regression. Still, their accuracy is worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Change\n",
    "In our second attempt at fine-tuning MLP to be better, we will increase the hidden layer size. Increasing the hidden layer size increases the model's capacity to learn from the data, however, too much can result in overfitting. We will evaluate whether this occurs by keeping track of our micro and macro precision/recall measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "dataset_results_MLP = []\n",
    "derived_dataset_1_results_MLP = []\n",
    "derived_dataset_2_results_MLP = []\n",
    "\n",
    "def kfold_eval(dataset, target):\n",
    "\tresultsMLP = []\n",
    "\tfor train_index, test_index in kf.split(dataset):\n",
    "\t\tx_train, x_test, y_train, y_test = dataset[train_index], dataset[test_index], target[train_index], target[test_index]\n",
    "\n",
    "\t\t_, _, results_MLP = mlp(x_train, x_test, y_train, y_test,hidden_layer_sizes='(200,)')\n",
    "\n",
    "\t\tresultsMLP.append(results_MLP)\n",
    "\t\n",
    "\treturn resultsMLP\n",
    "\n",
    "dataset_results_MLP = kfold_eval(dataset_tfidf, data['NPS Score'])\n",
    "derived_dataset_1_results_MLP = kfold_eval(derived_dataset_1_tfidf, derived_dataset1['Class'])\n",
    "derived_dataset_2_results_MLP = kfold_eval(derived_dataset_2_tfidf, derived_dataset2['Class'])\n",
    "\n",
    "dataset_results_MLP_avg = {metric: sum(result[metric] for result in dataset_results_MLP) / len(dataset_results_MLP) for metric in dataset_results_MLP[0]}\n",
    "derived_dataset_1_MLP_avg = {metric: sum(result[metric] for result in derived_dataset_1_results_MLP) / len(derived_dataset_1_results_MLP) for metric in derived_dataset_1_results_MLP[0]}\n",
    "derived_dataset_2_MLP_avg = {metric: sum(result[metric] for result in derived_dataset_2_results_MLP) / len(derived_dataset_2_results_MLP) for metric in derived_dataset_2_results_MLP[0]}\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Original Dataset):\")\n",
    "for metric, value in dataset_results_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Derived Dataset 1):\")\n",
    "for metric, value in derived_dataset_1_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Derived Dataset 2):\")\n",
    "for metric, value in derived_dataset_2_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
