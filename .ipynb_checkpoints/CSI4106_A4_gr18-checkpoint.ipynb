{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pbcc9QS1tnBN"
   },
   "source": [
    "**ASSIGNMENT 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2Eeke4Z_EkW"
   },
   "source": [
    "1. Group #: 18\n",
    "   Member Names: Natasha Hussain, Daanish Khan \n",
    "\n",
    "   Member Student Numbers: 300122562, 300126840 \n",
    "   \n",
    "   Report Title: Classification Empirical Study "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMUnCICdyBbs"
   },
   "source": [
    "**Derived Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "aCWgl6PLKTDY"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    precision_score, \n",
    "    recall_score\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX9WQWGSwU2D"
   },
   "source": [
    "You have been given a list of datasets in the assignment description. Choose one of the datasets and provide the link below and read the dataset using pandas. You should provide a link to your own Github repository even if you are using a reduced version of a dataset from your TA's repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:** Airline Passenger Reviews \n",
    "\n",
    "**Description:** This dataset provides 64,017 data samples of passenger reviews. They are separated into 3 categories - Passive (Neutral), Detractors (Negative), and Promoters (Positive). The reduced version we will be using contains 10,761 samples. \n",
    "\n",
    "Below we have 3 versions of the dataset that we will work with. The first dataset is simply a reduced dataset as we acquired from the source. Our second version of the datase is derived from the first to inlcude only part of speech tags. Our third and last dataset adds onto the second dataset by including part of speech tags as well as named entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1Xx4qMCLKTDb"
   },
   "outputs": [],
   "source": [
    "#Load the dataset you chose.\n",
    "url = 'https://raw.githubusercontent.com/NatashaNaima/AI-NLPs/main/reduced_file_AirPassengerReviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "wg24OUV81Xgm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/NatashaNaima/AI-NLPs/main/reduced_file_AirPassengerReviews.csv\n"
     ]
    }
   ],
   "source": [
    "print(url)\n",
    "# dataset 1 : the reduced dataset\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "AQ5nSY1HKTDd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_review</th>\n",
       "      <th>NPS Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>London to Izmir via Istanbul. First time I'd ...</td>\n",
       "      <td>Passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Istanbul to Bucharest. We make our check in i...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rome to Prishtina via Istanbul. I flew with t...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flew on Turkish Airlines IAD-IST-KHI and retu...</td>\n",
       "      <td>Promoter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mumbai to Dublin via Istanbul. Never book Tur...</td>\n",
       "      <td>Detractor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     customer_review  NPS Score\n",
       "0   London to Izmir via Istanbul. First time I'd ...    Passive\n",
       "1   Istanbul to Bucharest. We make our check in i...  Detractor\n",
       "2   Rome to Prishtina via Istanbul. I flew with t...  Detractor\n",
       "3   Flew on Turkish Airlines IAD-IST-KHI and retu...   Promoter\n",
       "4   Mumbai to Dublin via Istanbul. Never book Tur...  Detractor"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3pycllPKTDd"
   },
   "source": [
    "This is where you create the NLP pipeline. load() will download the correct model (English)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "wQtSi8XuKTDe"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccqFArDyKTDf"
   },
   "source": [
    "Applying the pipeline to every sentences creates a Document where every word is a Token object.\n",
    "\n",
    "Doc: https://spacy.io/api/doc\n",
    "\n",
    "Token: https://spacy.io/api/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcaeMUL2KTDg"
   },
   "outputs": [],
   "source": [
    "#Apply nlp pipeline to the column that has your sentences.\n",
    "data['tokenized'] = data['customer_review'].apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7i6ai1I8KTDg"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our derived datasets, we chose to use only adjectives for POS tagging. Since our datasets were reviews, we believed that adjectives would provide a clear enough picture of the general tone of each review to perform adequate classification. While we did consider doing a mix of tags to increase the amount of data we would have to work with, we believed in the end it would add more noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw0a_2ySyUo2"
   },
   "outputs": [],
   "source": [
    "#create empty dataframes that will store derived datasets\n",
    "\n",
    "derived_dataset1 = pd.DataFrame(columns = ['Class', 'pos'])\n",
    "derived_dataset2 = pd.DataFrame(columns = ['Class', 'pos-np'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yeak1tAOKTDi"
   },
   "outputs": [],
   "source": [
    "def get_pos(sentence, wanted_pos): #wanted_pos refers to the desired pos tagging\n",
    "    verbs = []\n",
    "    for token in sentence:\n",
    "        if token.pos_ in wanted_pos:\n",
    "            verbs.append(token.lemma_) # lemma returns a number. lemma_ return a string\n",
    "    return ' '.join(verbs) # return value is as a string and not a list for countVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "147NRzwKKTDj"
   },
   "outputs": [],
   "source": [
    "derived_dataset1['pos'] = data['tokenized'].apply(lambda sent : get_pos(sent, ['ADJ']))\n",
    "derived_dataset1['Class'] = data['NPS Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_bUg_fVKTDk"
   },
   "outputs": [],
   "source": [
    "derived_dataset1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuGv-NnfKTDj"
   },
   "outputs": [],
   "source": [
    "def get_entities(sentence, wanted_entities):\n",
    "    entity = []\n",
    "    for ent in sentence.ents:\n",
    "        if ent.label_ in wanted_entities:\n",
    "            entity.append(ent.text)\n",
    "            \n",
    "    return ' '.join(entity) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our second dataset, we included 3 named entities : organizations (airlines) and locations (travel destinations). These types of entities are relevant for classification as different airlines are known to meet certain levels of quality and different flights across airports experience varying levels of logistical consistency that affect flyers' experiences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_dataset2['ent-np'] = data['tokenized'].apply(lambda sent : get_entities(sent, ['ORG', 'GPE']))\n",
    "derived_dataset2['pos-np'] = data['tokenized'].apply(lambda sent : get_pos(sent, ['ADJ']))\n",
    "derived_dataset2['Class'] = data['NPS Score']\n",
    "derived_dataset2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pX4RgKhKTDk"
   },
   "source": [
    "Now that we have our derived datasets, we can move to perform our classificaton task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GhniwHtzfQt"
   },
   "source": [
    "**Perform Classification Task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "dataset_tfidf = TfidfVectorizer().fit_transform(data.customer_review)\n",
    "derived_dataset_1_tfidf = TfidfVectorizer().fit_transform(derived_dataset1.pos)\n",
    "derived_dataset_2_tfidf = TfidfVectorizer().fit_transform(derived_dataset2['pos-np'].to_numpy() + derived_dataset2['ent-np'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistical Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistical regression estimates the probability of an outcome using a logistic function. The model is trained to find the optimal parameters in our dataset to maximize the likelihood of a particular review, and it provides a decision boundary for classification.\n",
    "\n",
    "To start we set out with mostly default parameters for logistical regression:\n",
    "\n",
    "We set our maximum interations to 1000 so that if convergence doesn't occur before then, our function will not take to long to run.\n",
    "\n",
    "We start here with C=1 to have a moderate regularization. Regularization is a technique used to prevent overfitting. A smaller C value specifies strong regularization, while a larger involves weaker regularization. \n",
    "\n",
    "We used Limited-memory Broyden–Fletcher–Goldfarb–Shanno ('lbfgs') for our optimization algorithm. Logistic regression can be solved using different optimization algorithms. Different solvers have different characteristics that perform better or worse dependant on the dataset size, features, and other factors. We chose LM BFGS because it is a popular choice for logistical regression on small to medium sized datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistical_regression(x_train, x_test, y_train, y_test, C=1, solver='lbfgs'):\n",
    "\tmodel = LogisticRegression(max_iter=1000, C=1, solver='lbfgs').fit(x_train, y_train)\n",
    "\n",
    "\t# Make prediction from model\n",
    "\ty_pred = model.predict(x_test)\n",
    "\n",
    "\t# calculate accuracy and f1\n",
    "\taccuracy = accuracy_score(y_pred, y_test)\n",
    "\tf1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "\t# calculating micro and macro precision/recall\n",
    "\tmicro_precision = precision_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\tmicro_recall = recall_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "\t# calculating macro precision/recall \n",
    "\tmacro_precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\tmacro_recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\tevaluation = {'accuracy': accuracy, 'f1': f1, 'macro_p': macro_precision, 'macro_r':macro_recall, 'micro_p':micro_precision, 'micro_r': micro_recall}\n",
    "\treturn model, y_pred, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MLP classification refers to the use of a Multi-Layer Perceptron for solving classification problems. They are known for their ability to capture complex relationships in data and perform well on a variety of tasks. However, they may require more data and computational resources compared to simpler models, and proper tuning of hyperparameters is crucial for achieving good results.\n",
    "\n",
    "To start, we used the default parameters to classify our dataset. There are many paramters that can be changed and fine-tuned, but some notable ones to discuss here are:\n",
    "\n",
    "Hidden layer sizes: This paramter determines the number of neurons in each hidden layer. The default, that we use, is 100. \n",
    "\n",
    "Activation function: The activation function used in the hidden layers. The default, that we use, is rectified linear unit ('relu').\n",
    "\n",
    "Solver : The optimization algorithm used for weight opitmization. The default, that we use, is adam.\n",
    "\n",
    "Maximum iterations : The number of iterations for the solver to converge. When the model is not converging, we would set this to be very high so that we can choose a time to force it to converge. The default, that we use, is 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def mlp(x_train, x_test, y_train, y_test):\n",
    "\tmodel = MLPClassifier().fit(x_train, y_train)\n",
    "\n",
    "\t# Make prediction from model\n",
    "\ty_pred = model.predict(x_test)\n",
    "\n",
    "\t# calculate accuracy and f1\n",
    "\taccuracy = accuracy_score(y_pred, y_test)\n",
    "\tf1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "\t# calculating micro and macro precision/recall\n",
    "\tmicro_precision = precision_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\tmicro_recall = recall_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "\t# calculating macro precision/recall \n",
    "\tmacro_precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\tmacro_recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\tevaluation = {'accuracy': accuracy, 'f1': f1, 'macro_p': macro_precision, 'macro_r':macro_recall, 'micro_p':micro_precision, 'micro_r': micro_recall}\n",
    "\treturn model, y_pred, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "dataset_results_LR = []\n",
    "derived_dataset_1_results_LR = []\n",
    "derived_dataset_2_results_LR = []\n",
    "\n",
    "dataset_results_MLP = []\n",
    "derived_dataset_1_results_MLP = []\n",
    "derived_dataset_2_results_MLP = []\n",
    "\n",
    "def kfold_eval(dataset, target):\n",
    "\tresultsLR = []\n",
    "\tresultsMLP = []\n",
    "\tfor train_index, test_index in kf.split(dataset):\n",
    "\t\tx_train, x_test, y_train, y_test = dataset[train_index], dataset[test_index], target[train_index], target[test_index]\n",
    "\n",
    "\t\t_, _, results_LR = logistical_regression(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\t\t_, _, results_MLP = mlp(x_train, x_test, y_train, y_test)\n",
    "\n",
    "\t\tresultsLR.append(results_LR)\n",
    "\t\tresultsMLP.append(results_MLP)\n",
    "\t\n",
    "\treturn resultsLR, resultsMLP\n",
    "\n",
    "dataset_results_LR, dataset_results_MLP = kfold_eval(dataset_tfidf, data['NPS Score'])\n",
    "derived_dataset_1_results_LR, derived_dataset_1_results_MLP = kfold_eval(derived_dataset_1_tfidf, derived_dataset1['Class'])\n",
    "derived_dataset_2_results_LR, derived_dataset_2_results_MLP = kfold_eval(derived_dataset_2_tfidf, derived_dataset2['Class'])\n",
    "\n",
    "dataset_results_LR_avg = {metric: sum(result[metric] for result in dataset_results_LR) / len(dataset_results_LR) for metric in dataset_results_LR[0]}\n",
    "derived_dataset_1_LR_avg = {metric: sum(result[metric] for result in derived_dataset_1_results_LR) / len(derived_dataset_1_results_LR) for metric in derived_dataset_1_results_LR[0]}\n",
    "derived_dataset_2_LR_avg = {metric: sum(result[metric] for result in derived_dataset_2_results_LR) / len(derived_dataset_2_results_LR) for metric in derived_dataset_2_results_LR[0]}\n",
    "\n",
    "dataset_results_MLP_avg = {metric: sum(result[metric] for result in dataset_results_MLP) / len(dataset_results_MLP) for metric in dataset_results_MLP[0]}\n",
    "derived_dataset_1_MLP_avg = {metric: sum(result[metric] for result in derived_dataset_1_results_MLP) / len(derived_dataset_1_results_MLP) for metric in derived_dataset_1_results_MLP[0]}\n",
    "derived_dataset_2_MLP_avg = {metric: sum(result[metric] for result in derived_dataset_2_results_MLP) / len(derived_dataset_2_results_MLP) for metric in derived_dataset_2_results_MLP[0]}\n",
    "\n",
    "print(\"Average Results for Logistic Regression With Default Params (Original Dataset):\")\n",
    "for metric, value in dataset_results_LR_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for Logistic Regression With Default Params (Derived Dataset 1):\")\n",
    "for metric, value in derived_dataset_1_LR_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for Logistic Regression With Default Params (Derived Dataset 2):\")\n",
    "for metric, value in derived_dataset_2_LR_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Original Dataset):\")\n",
    "for metric, value in dataset_results_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Derived Dataset 1):\")\n",
    "for metric, value in derived_dataset_1_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage Results for MLP With Default Params (Derived Dataset 2):\")\n",
    "for metric, value in derived_dataset_2_MLP_avg.items():\n",
    "\tprint(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***[EXPLAIN RESULTS HERE + ADD CHARTS]***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Changes for MLP\n",
    "\n",
    "***[EXPLANATION FOR PARAMETER CHANGES AND WHAT IS BEING CHANGED]***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### References\n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
